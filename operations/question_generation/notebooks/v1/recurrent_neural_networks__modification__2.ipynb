{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc123a0",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "**Python Topics** - deep_learning > recurrent_neural_networks\n",
    "\n",
    "**Type** - modification\n",
    "\n",
    "**Target Number of Turns (User + Assistant)** - 2+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66cd2cf",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5d88a",
   "metadata": {},
   "source": [
    "**User**\n",
    "\n",
    "I need to add a bidirectional wrapper to the existing LSTM layer in this Keras code. How should I modify it? Here's what I have so far:\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(30, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
